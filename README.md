# Асинхронный парсер документов PEP на базе фреймворка Scrapy.

## Возможности парсера:
- Выводит список всех PEP: номер, название и статус,
- Cодержbn сводку по статусам PEP — 
сколько найдено документов в каждом статусе (статус, количество)

## Как запустить проект:

#### Клонируйте репозиторий:

```
git clone git@github.com:DianaKim9319/scrapy_parser_pep.git
```

#### Cоздайте и активируйте виртуальное окружение:

```
python -m venv venv
```

```
source venv/Scripts/activate
```

#### Установите зависимости:

```
pip install -r requirements.txt
```
#### Запустите парсер:
```
scrapy crawl pep
```

## Парсер сохраняет данные в файлы .csv в директорию results/
- Файл со списком PEP должны быть именованы  в формате
``results/pep_ДатаВремя.csv``, например — pep_2029-01-31T23-55-00.csv.
- Файл со сводкой по статусам в формате
``results/pep_ДатаВремя.csv``, например — status_summary_2029-01-31_23-55-00.csv